{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e34a32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    object\n",
       "Word          object\n",
       "POS           object\n",
       "Tag           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load data from CSV file -> got this dataset from kaggle\n",
    "data = pd.read_csv('/Users/prajwalhegde/Downloads/ner_dataset.csv', encoding=\"latin1\")\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "59cbe3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/9m1j4l7s593g3365mw4qsq2r0000gn/T/ipykernel_46114/492576798.py:3: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for index, sentence_num in data['Sentence #'].iteritems():\n"
     ]
    }
   ],
   "source": [
    "curr_sentence = 1\n",
    "# Iterate through the \"Word\" column using .iteritems()\n",
    "for index, sentence_num in data['Sentence #'].iteritems():\n",
    "    #print(f\"Index: {index}, Word: {sentence_num}\")\n",
    "    if (pd.isna(sentence_num)):\n",
    "        data.loc[index, 'Sentence #'] = curr_sentence\n",
    "    else:\n",
    "        curr_sentence = int(sentence_num.split(': ')[1])\n",
    "        data.loc[index, 'Sentence #'] = curr_sentence\n",
    "#df['Sentence #'] = df['Sentence #'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "e342b1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #       Word  POS Tag\n",
       "1048570      47959       they  PRP   O\n",
       "1048571      47959  responded  VBD   O\n",
       "1048572      47959         to   TO   O\n",
       "1048573      47959        the   DT   O\n",
       "1048574      47959     attack   NN   O"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "a6d1121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #     int64\n",
       "Word          object\n",
       "POS           object\n",
       "Tag           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentence #'] = data['Sentence #'].astype('int64')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "21c0b1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Thousands', 16],\n",
       " ['of', 16],\n",
       " ['demonstrators', 16],\n",
       " ['have', 16],\n",
       " ['marched', 16],\n",
       " ['through', 16],\n",
       " ['London', 2],\n",
       " ['to', 16],\n",
       " ['protest', 16],\n",
       " ['the', 16],\n",
       " ['war', 16],\n",
       " ['in', 16],\n",
       " ['Iraq', 2],\n",
       " ['and', 16],\n",
       " ['demand', 16],\n",
       " ['the', 16],\n",
       " ['withdrawal', 16],\n",
       " ['of', 16],\n",
       " ['British', 3],\n",
       " ['troops', 16],\n",
       " ['from', 16],\n",
       " ['that', 16],\n",
       " ['country', 16],\n",
       " ['.', 16]]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_encoder = LabelEncoder()\n",
    "data['Tag_index'] = tag_encoder.fit_transform(data['Tag'])\n",
    "\n",
    "# Group data by sentence and create sequences of words and tags\n",
    "grouped_data = data.groupby('Sentence #')[['Word', 'Tag_index']].apply(lambda x: x.values.tolist()).to_dict()\n",
    "grouped_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "5a1e2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grouped data into sequences of sentences and labels\n",
    "sentences = []\n",
    "labels = []\n",
    "for sentence, group in grouped_data.items():\n",
    "    words = [item[0] for item in group]\n",
    "    tags = [item[1] for item in group]\n",
    "    sentences.append(words)\n",
    "    labels.append(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c4e8f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "word_to_index['UNK'] = len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "adcf76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-geo\n"
     ]
    }
   ],
   "source": [
    "index_to_tag = {idx: tag for idx, tag in enumerate(tag_encoder.classes_)}\n",
    "numerical_index = 2\n",
    "tag_label = index_to_tag[numerical_index]\n",
    "print(tag_label)  # This will print the original tag label associated with index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "d4525909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 1586, 3938, 2679, 151, 846, 4648, 68, 3006, 11, 4649, 21]\n"
     ]
    }
   ],
   "source": [
    "sentences_indices = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence_indices = [word_to_index.get(word, word_to_index['UNK']) for word in sentence]\n",
    "    sentences_indices.append(sentence_indices)\n",
    "print (sentences_indices[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "4b89428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(index_to_tag)\n",
    "\n",
    "\n",
    "# Find the maximum sequence length for both X and y\n",
    "max_sequence_length = max(max(len(sequence) for sequence in sentences_indices), max(len(sequence) for sequence in labels))\n",
    "\n",
    "# Pad the input sequences (X) to match the maximum sequence length\n",
    "X = pad_sequences(sentences_indices, maxlen=max_sequence_length, padding='post', value=0)  # Assuming '0' is the padding value\n",
    "\n",
    "# Pad the target sequences (y) to match the maximum sequence length\n",
    "y = pad_sequences(labels, maxlen=max_sequence_length, padding='post', value=0)  # Assuming '0' is the padding value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "81b8dbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14  9 15  1 16 17 18 19 20 21\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "[16 16 16 16 16 16  2 16 16 16 16 16  2 16 16 16 16 16  3 16 16 16 16 16\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "83a59fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "2d2b80af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14  9 15  1 16 17 18 19 20 21\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "[16 16 16 16 16 16  2 16 16 16 16 16  2 16 16 16 16 16  3 16 16 16 16 16\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ee45dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "c801a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "print (max_sequence_length)\n",
    "print(len(y[0]))\n",
    "print(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "6fdaa0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1199/1199 [==============================] - 57s 46ms/step - loss: 0.1140 - accuracy: 0.9746 - val_loss: 0.0313 - val_accuracy: 0.9913\n",
      "Epoch 2/2\n",
      "1199/1199 [==============================] - 56s 46ms/step - loss: 0.0231 - accuracy: 0.9933 - val_loss: 0.0238 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d7b6130a0>"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already prepared X_train, X_test, y_train, y_test as described earlier\n",
    "\n",
    "# Define hyperparameters\n",
    "embedding_dim = 100  # Choose an appropriate value based on your data\n",
    "lstm_units = 64     # Number of LSTM units\n",
    "num_epochs = 2     # Number of training epochs\n",
    "batch_size = 32     # Batch size\n",
    "num_tags = 17       # Number of unique tag classes\n",
    "\n",
    "# Build the bidirectional LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(units=num_tags, activation='softmax')))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "88b9d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "75/75 [==============================] - 2s 32ms/step - loss: 0.0238 - accuracy: 0.9928\n",
      "test loss: 0.02381025068461895 \n",
      "test accuracy: 0.9928426146507263 \n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss: {} \".format(results[0]))\n",
    "print(\"test accuracy: {} \".format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "16138aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  345   163    93     9   703     1   110    68  6635  7532    93  1165\n",
      "  9225  9657 17042    93   172   363   496    20  1461  1859  3584  3585\n",
      "     7  7665  1848   161   898    21     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[16  7 16 16 16 16  2 16  2 10 16  5 13 13 13 16 16  7 16 16 16 16 16 16\n",
      " 16 16 16 16 16 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "300/300 [==============================] - 4s 11ms/step\n",
      "(9592, 104, 17)\n"
     ]
    }
   ],
   "source": [
    "print (X_test[0])\n",
    "print (y_test[0])\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print (predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1d6f13fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35178\n",
      "[ 2502     1     2  3569    11  3630 12371   223    45  1005   329 35178\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predictions for the example sentence:\n",
      "['O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'B-gpe', 'I-org', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art', 'B-art']\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your compiled Keras model\n",
    "\n",
    "# Example sentence\n",
    "example_sentence = \"Millions of demonstrators gathered in Times Square for a cold American beverage.\"\n",
    "\n",
    "print (word_to_index['UNK'])\n",
    "\n",
    "# Tokenize the sentence and convert to word indices\n",
    "words = example_sentence.split()\n",
    "words2 = example_sentence2.split()\n",
    "word_indices = [word_to_index.get(word, word_to_index['UNK']) for word in words]\n",
    "# Pad the sequence\n",
    "expected_sequence_length = 104\n",
    "padded_sequence = pad_sequences([word_indices], maxlen=expected_sequence_length, padding='post', value=0)\n",
    "\n",
    "print (padded_sequence[0])\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "novel_predictions = model.predict(padded_sequence)\n",
    "\n",
    "# Print predictions\n",
    "ex_tags = []\n",
    "print(\"Predictions for the example sentence:\")\n",
    "for prob in novel_predictions[0]:\n",
    "    ex_tags.append(index_to_tag[np.argmax(prob)])\n",
    "print (ex_tags)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c23b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9667f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
